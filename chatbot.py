# -*- coding: utf-8 -*-
"""chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pkV-0FX8pELMOs9oDQszmYHPRAP6AJ1H
"""

!pip install langchain-community
from langchain import HuggingFaceHub
import os
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "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"


print(os.environ.get("HUGGINGFACEHUB_API_TOKEN"))
!pip install langchain-huggingface
!pip install huggingface_hub
!pip install langchain
!pip install transformers
!pip install accelerate
!pip install bitsandbytes
!pip install streamlit

import streamlit as st

def get_huggingface_response(question):
  llm_huggingface = HuggingFaceHub(repo_id="google/flan-t5-large",model_kwargs={"max_length": 128, "temperature": 0.7},)
  response=llm_huggingface(question)
  return response[0]['generated_text']

#initialize streamlit app

st.set_page_config(page_title="HuggingFace Chatbot")
st.header("HuggingFace Chatbot")
input=st.text_input("Input: ",key="input")
submit=st.button("Ask the question")

if submit and input:
  response=get_huggingface_response(input)
  st.subheader("Output: ")
  st.write(response)

!streamlit run chatbot.ipynb

